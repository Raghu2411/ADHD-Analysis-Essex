{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding the Data\n",
        "\n",
        "Y -> There are 2 targets\n",
        " 1. ADHD diagnosis (0- None, 1- ADHD)\n",
        " 2. Sex (0- Male, 1 - Female)\n",
        "\n",
        "X ->\n",
        "1. Metadata A + B = Socio Demographics Information (Quantitative + Categorical)\n",
        "2. Functional MRI Matrices  (Dont Touch)\n",
        "\n",
        "Combine these 2 for EDA and Model Training.\n",
        "\n",
        "---\n",
        "\n",
        "### Data Files\n",
        "\n",
        "- LABELS: ADHD diagnosis and sex.\n",
        "- fMRI Connectome Matrices: High-dimensional numerical data representing brain connectivity.\n",
        "- Socio-Demographic Data: A mix of categorical and numerical features (e.g., handedness, education level, parenting info, emotions).\n",
        "\n",
        "---\n",
        "\n",
        "Others\n",
        "\n",
        "- Instrument_Description - Description about the types of Tests taken.\n",
        "- EHQ ‚Äì Edinburgh Handedness Questionnaire\n",
        "- APQ ‚ÄìAlabama Parenting Questionnaire\n",
        "- SDQ ‚Äì Strength and Difficulties Questionnaire.\n",
        "\n",
        "I believe these things are for knowledge and may be useful for features development and understanding."
      ],
      "metadata": {
        "id": "iJ77sx2kmtwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "‚úÖ Missing data should be handled before checking relationships/correlations.\n",
        "\n",
        "‚úÖ Normalization/standardization should be done after checking relationships/correlations to avoid distorting the data."
      ],
      "metadata": {
        "id": "2yk8-V_nrlZV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1v12VlOgGpJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Deeper Understanding of Data\n",
        "\n",
        "\n",
        "‚úÖ Steps:\n",
        "\n",
        "- Load the dataset (CSV, Excel, SQL, JSON, etc.).\n",
        "- Check the data structure: Number of rows & columns (df.shape).\n",
        "- Inspect column names & data types (df.info()).\n",
        "- Check the first few rows (df.head()).\n",
        "Look at variable descriptions (refer to data dictionary)."
      ],
      "metadata": {
        "id": "NoZsj7HetkOf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PeFPvFWmtbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-kPrJECmtTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NhNy498uIF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2Ô∏è‚É£ Data Cleaning & Handling Missing Values\n",
        "\n",
        "üí° Goal: Fix inconsistencies, deal with NaNs, and clean the data\n",
        "\n",
        "‚úÖ Steps:\n",
        "\n",
        "- Identify missing values (df.isnull().sum()).\n",
        "- Decide how to handle NaNs:\n",
        "-- Drop rows (df.dropna()).\n",
        "-- Fill with mean/median (df.fillna(df.mean())).\n",
        "-- Fill categorical NaNs with mode (df.fillna(df.mode()[0])).\n",
        "\n",
        "- Remove duplicates (df.duplicated().sum() ‚Üí df.drop_duplicates()).\n",
        "- Fix inconsistencies (e.g., standardize categorical values: \"Male\"/\"male\" ‚Üí \"Male\")."
      ],
      "metadata": {
        "id": "l4nzm5tUuIj7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJTHpaNuuIDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geqhKujguIAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3Ô∏è‚É£ Feature Understanding & Exploration\n",
        "\n",
        "üí° Goal: Analyze the features, distributions, and relationships\n",
        "\n",
        "‚úÖ Steps:\n",
        "\n",
        "### A. Univariate Analysis (Individual Feature Analysis)\n",
        "\n",
        "üìä For numerical variables:\n",
        "\n",
        "- Summary statistics (df.describe()).\n",
        "- Histograms (sns.histplot(df['column'])).\n",
        "- Box plots (to check for outliers).\n",
        "\n",
        "üìä For categorical variables:\n",
        "\n",
        "- Value counts (df['column'].value_counts()).\n",
        "- Bar plots (sns.countplot(x=df['column'])).\n",
        "\n",
        "### B. Bivariate Analysis (Feature-to-Feature Relationships)\n",
        "üìå Numerical vs. Numerical:\n",
        "\n",
        "- Correlation matrix (df.corr(), sns.heatmap(df.corr())).\n",
        "- Scatter plots (sns.scatterplot(x='feature1', y='feature2', data=df)).\n",
        "\n",
        "üìå Categorical vs. Numerical:\n",
        "\n",
        "- Boxplots (sns.boxplot(x='category', y='numerical', data=df)).\n",
        "- Groupby statistics (df.groupby('category')['numerical'].mean()).\n",
        "\n",
        "üìå Categorical vs. Categorical:\n",
        "\n",
        "- Cross-tabulation (pd.crosstab(df['cat1'], df['cat2'])).\n",
        "- Stacked bar charts."
      ],
      "metadata": {
        "id": "4aMjBEzXuch0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ommBje3FuH9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZXrfaRruH6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4Ô∏è‚É£ Handling Outliers & Transformations\n",
        "\n",
        "üí° Goal: Detect and manage extreme values for better model performance\n",
        "\n",
        "‚úÖ Steps:\n",
        "\n",
        "- Detect outliers using box plots or Z-score (scipy.stats.zscore()).\n",
        "- Remove or cap extreme values (df[df['column'] < threshold]).\n",
        "- Apply transformations if needed:\n",
        "-- Log transformation for skewed data.\n",
        "-- Scaling (MinMaxScaler, StandardScaler)."
      ],
      "metadata": {
        "id": "xwVCDEV-u8kV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKOsJQ_FuH3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xfsRTRRjuHxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5Ô∏è‚É£ Feature Engineering & Encoding\n",
        "\n",
        "üí° Goal: Transform data into a format suitable for machine learning\n",
        "\n",
        "‚úÖ Steps:\n",
        "\n",
        "üìå Encoding categorical variables\n",
        "\n",
        "- One-hot encoding (pd.get_dummies(df, columns=['categorical_column'])).\n",
        "- Label encoding (sklearn.preprocessing.LabelEncoder()).\n",
        "\n",
        "üìå Feature Engineering\n",
        "\n",
        "- Create new features (e.g., age groups from age).\n",
        "- Extract date components (year, month, etc.).\n",
        "\n",
        "üìå Dimensionality Reduction (if needed)\n",
        "\n",
        "- PCA (Principal Component Analysis) for high-dimensional data."
      ],
      "metadata": {
        "id": "hkKyvNmuvHyE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KzH2cJiVvHiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GsNeQZ4fvHgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6Ô∏è‚É£ Splitting Data for Training & Model Preparation\n",
        "\n",
        "üí° Goal: Prepare dataset for modeling\n",
        "\n",
        "‚úÖ Steps:\n",
        "\n",
        "- Separate features and target (X = df.drop(columns=['target']), y = df['target']).\n",
        "- Train-test split (train_test_split(X, y, test_size=0.2, random_state=42)).\n",
        "- Check class distribution (for imbalanced data).\n",
        "- Balance data if necessary (SMOTE, oversampling)."
      ],
      "metadata": {
        "id": "MsmutgQcvfT1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsFAcroyvHdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z7_cx3R4vHak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58fVzL_lvHXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pxNu4RSvHTj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}